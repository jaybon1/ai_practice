{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 경사 하강법 (에포크 5)\n",
      "시간 (running_time)                    : 0.012696999940090\n",
      "비용 (cost)                            : 1462.610746090536850\n",
      "효율 (cost * running_time)             : 18.570768555486364\n",
      "\n",
      "확률적 경사 하강법 (에포크 5)\n",
      "시간 (running_time)                    : 18.386413599946536\n",
      "비용 (cost)                            : 0.005530812705267\n",
      "효율 (cost * running_time)             : 0.101691809942882\n",
      "\n",
      "미니 배치 경사 하강법 (에포크 5)\n",
      "시간 (running_time)                    : 0.193320400081575\n",
      "비용 (cost)                            : 0.642078256011342\n",
      "효율 (cost * running_time)             : 0.124126825335792\n",
      "\n",
      "미니 배치 랜덤 경사 하강법 (에포크 5)\n",
      "시간 (running_time)                    : 0.526300200028345\n",
      "비용 (cost)                            : 2.386548675616968\n",
      "효율 (cost * running_time)             : 1.256041045354592\n",
      "\n",
      "------------------------------------------------------------\n",
      "효율 순서\n",
      "0.101691809942882 ( 확률적 )\n",
      "0.124126825335792 ( 미니 배치 )\n",
      "1.256041045354592 ( 미니 배치 랜덤 )\n",
      "18.570768555486364 ( 배치 )\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 import\n",
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 배치 경사 하강법\n",
    "def batch_gradient_descent(x : np.ndarray, y : np.ndarray, theta : np.ndarray, alpha : float, m : int, epoch : int, batchSize : int):\n",
    "    xTrans = x.transpose()\n",
    "    for i in range(0, epoch):\n",
    "        hypothesis = np.dot(x, theta)\n",
    "        loss = hypothesis - y\n",
    "        cost = np.sum(loss ** 2) / (2 * m)\n",
    "        gradient = np.dot(xTrans, loss) / m\n",
    "        theta = theta - alpha * gradient\n",
    "    return (\"배치\" , cost, theta)\n",
    "\n",
    "\n",
    "# 확률적 경사 하강법\n",
    "def stochastic_gradient_descent(x : np.ndarray, y : np.ndarray, theta : np.ndarray, alpha : float, m : int, epoch : int, batchSize : int):\n",
    "    xTrans = x.transpose()\n",
    "    for i in range(0, epoch):\n",
    "        for j in range(0, m):\n",
    "            hypothesis = np.dot(x[j:j + 1, :], theta)\n",
    "            loss = hypothesis - y[j:j + 1]\n",
    "            cost = np.sum(loss ** 2) / (2 * m)\n",
    "            gradient = np.dot(xTrans[:, j:j + 1], loss) / m\n",
    "            theta = theta - alpha * gradient\n",
    "    return (\"확률적\" , cost, theta)\n",
    "\n",
    "# 미니 배치 경사 하강법\n",
    "def mini_batch_gradient_descent(x : np.ndarray, y : np.ndarray, theta : np.ndarray, alpha : float, m : int, epoch : int, batchSize : int):\n",
    "    xTrans = x.transpose()\n",
    "    for i in range(0, epoch):\n",
    "        for j in range(0, m, batchSize):\n",
    "            hypothesis = np.dot(x[j:j + batchSize, :], theta)\n",
    "            loss = hypothesis - y[j:j + batchSize]\n",
    "            cost = np.sum(loss ** 2) / (2 * m)\n",
    "            gradient = np.dot(xTrans[:, j:j + batchSize], loss) / m\n",
    "            theta = theta - alpha * gradient\n",
    "    return (\"미니 배치\" , cost, theta)\n",
    "\n",
    "# 미니 배치 경사 하강법 + 미니 배치에서 데이터 30개를 랜덤하게 뽑아서 사용\n",
    "def mini_batch_random_gradient_descent(x : np.ndarray, y : np.ndarray, theta : np.ndarray, alpha : float, m : int, epoch : int, batchSize : int):\n",
    "    xTrans = x.transpose()\n",
    "    for i in range(0, epoch):\n",
    "        for j in range(0, m, batchSize):\n",
    "            # 0~99까지의 중복되지 않는 랜덤한 정수 30개 생성\n",
    "            random_idx_list = np.random.choice(100, 30, replace=False)\n",
    "            # 배열에서 random_idx_list 안에 있는 인덱스만 추출\n",
    "            hypothesis = np.dot(x[j:j + batchSize, :][random_idx_list], theta)\n",
    "            loss = hypothesis - y[j:j + batchSize][random_idx_list]\n",
    "            cost = np.sum(loss ** 2) / (2 * m)\n",
    "            gradient = np.dot(xTrans[:, j:j + batchSize][:, random_idx_list], loss) / m\n",
    "            theta = theta - alpha * gradient\n",
    "    return (\"미니 배치 랜덤\" , cost, theta)\n",
    "\n",
    "# 경사하강법 속도 및 정확도 비교\n",
    "def checkSpeedAndEfficiency(func_list : list, x : np.ndarray, y : np.ndarray, theta : np.ndarray, alpha : float, m : int, epoch : int, batchSize : int):\n",
    "    test_list = []\n",
    "    for func in func_list:\n",
    "        \n",
    "        start = timeit.default_timer()\n",
    "        result = func(x, y, theta, alpha, m, epoch, batchSize)\n",
    "        stop = timeit.default_timer()\n",
    "        \n",
    "        name, cost, th = result\n",
    "        running_time = stop - start\n",
    "        \n",
    "        cost_per_running_time = cost * running_time\n",
    "        print(name, f\"경사 하강법 (에포크 {epoch})\")\n",
    "        print(\"시간 (running_time)                    :\", format(running_time, \".15f\"))\n",
    "        print(\"비용 (cost)                            :\", format(cost, \".15f\"))\n",
    "        print(\"효율 (cost * running_time)             :\", format(cost_per_running_time, \".15f\"))\n",
    "        print()\n",
    "        # test_list.append({\"name\": name, \"time\": running_time, \"cost\": cost, \"cost_per_time\": cost_per_running_time})\n",
    "        test_list.append({\"name\": name, \"cost_per_time\": cost_per_running_time, running_time: running_time, cost: cost})\n",
    "        test_list = sorted(test_list, key=lambda x: x[\"cost_per_time\"])\n",
    "    \n",
    "    print(\"-\"*60)\n",
    "    print(\"효율 순서\")\n",
    "    for item in test_list:\n",
    "        # print(f\"{count}.\" , item[\"name\"], \":\", format(item[\"cost_per_time\"], \".15f\"))\n",
    "        print( format(item[\"cost_per_time\"], \".15f\"), \"(\", item[\"name\"], \")\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# func_list = [batch_gradient_descent]\n",
    "\n",
    "# # 함수 리스트\n",
    "func_list = [batch_gradient_descent, \\\n",
    "            stochastic_gradient_descent, \\\n",
    "            mini_batch_gradient_descent, \\\n",
    "            mini_batch_random_gradient_descent]\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('data/byong_data_set1.csv')\n",
    "\n",
    "# 데이터 세팅\n",
    "x = df[['height', 'weight']].values # 특성 (feature)\n",
    "y = df[['bmi']].values # 라벨 (label)\n",
    "m, n = np.shape(x) # m : 샘플 개수, n : 특성 개수\n",
    "epoch = 5 # 에포크 (epoch)\n",
    "theta = np.ones(n).reshape(-1, 1) # 임의 가중치\n",
    "alpha = 0.00001 # 학습률\n",
    "batchSize = 100 # 미니 배치 크기\n",
    "\n",
    "# 체크 \n",
    "checkSpeedAndEfficiency(func_list, x, y, theta, alpha, m, epoch, batchSize)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e10ef16274dd72e574b8fa73b58450b957d8421a2901baded3cca26fcf5dda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
